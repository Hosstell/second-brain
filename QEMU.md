---
tags:
---
-- **Установка**
```bash
sudo apt update
sudo apt install qemu-kvm libvirt-daemon-system libvirt-clients bridge-utils
```

-- **Запуск**
```bash
qemu-system-x86_64 -boot d -cdrom ubuntu-25.04-live-server-amd64.iso -m 4G -enable-kvm
```
**`qemu-system-x86_64`**: Это основная команда для запуска QEMU на системах с архитектурой x86_64.
**`-boot d`**: Эта опция указывает QEMU, с какого устройства следует загружаться. Значение `d` означает загрузку с CD-ROM. Это значит, что виртуальная машина будет пытаться загрузиться с указанного ISO-образа.
**`-cdrom ubuntu-25.04-live-server-amd64.iso`**: эта опция указывает путь к ISO-образу, который будет использоваться в качестве виртуального CD-ROM. В данном случае это образ Ubuntu Server версии 25.04. Виртуальная машина будет загружаться с этого образа.
**`-m 4G`**:  объем оперативной памяти (RAM)
**`-enable-kvm`**: эта опция включает поддержку KVM (Kernel-based Virtual Machine), что позволяет использовать аппаратную виртуализацию для улучшения производительности виртуальной машины. KVM использует возможности процессора для ускорения выполнения команд виртуальной машины.

**PS:** все созданные файл в системе будут сохранены до окончания сессии. Без указания виртуального диска, они будут хранится в ram. Для сохранения файлов между сессиями нужно создать виртуальный диск.

-- **Создание виртуального диска**
```bash
qemu-img create -f qcow2 my_virtual_disk.qcow2 20G
```


-- **Physical Volume, Volume Group, Logical Volume**
1. **Physical Volume (PV):**
    - Это базовый строительный блок LVM, представляющий собой физическое устройство хранения (например, жесткий диск, SSD или раздел диска), которое инициализировано для использования с LVM.
    - PV предоставляет пространство, которое может быть использовано для создания Volume Groups (VG).
      
2. **Volume Group (VG):**
    - VG объединяет один или несколько PV в один пул пространства. Это позволяет использовать несколько физических устройств как единое целое.
    - VG предоставляет пространство, из которого можно создавать Logical Volumes (LV).
      
3. **Logical Volume (LV):**
    - LV создается из пространства, предоставленного VG. Это логические разделы, которые выглядят и работают как обычные разделы диска, но с большей гибкостью в управлении.
    - LV может быть легко изменен в размере, перемещен или удален без необходимости изменять физическую структуру дисков.
    
-- **Взаимосвязь компонентов:**
- **PV → VG:** Один или несколько PV могут быть объединены в одну VG. Это позволяет агрегировать пространство с нескольких физических устройств.
- **VG → LV:** Из пространства, предоставленного VG, можно создавать несколько LV. Это позволяет гибко распределять пространство между различными логическими томами.

**Пример:**
```bash
# Создание PV
sudo pvcreate /dev/sdX 
sudo pvcreate /dev/sdY

# Создание VG из нескольких PV
sudo vgcreate my_volume_group /dev/sdX /dev/sdY

# Создание LV из VG
sudo lvcreate -n my_logical_volume -L 20G my_volume_group
```
Таким образом, LVM предоставляет гибкую и мощную систему управления дисковым пространством, позволяя эффективно использовать ресурсы и легко изменять конфигурацию хранилищ в зависимости от потребностей.

**PS (ВАЖНО):**
- Прежде чем инициализировать физический том (PV) в LVM, устройство (например, диск или раздел) должно быть подготовлено на уровне операционной системы. 
- LVM лишь абстракция над инструментами, которые работают на уровне ос. К примеру, в моем случае использования QEMU и установки новой ос на виртуальный диск, была предложена вот такая схема:

1. Ubuntu ОС. Диск 500 гб
2. Выделяем 20 гб для QEMU. Создаем виртуальный диск. Для ос, запущенные через QEMU, данный диск будет выглядеть как физический.
3. При установки ос разделяем виртуальный диск на логические тома:
	1. 10 гб - ubuntu-vg (группа для тома) - ubuntu-lv (логический том) смонтированный в /. Для этого используется LVM
	2. 1 гб - логический том для /boot. Напрямую монтирует в диск.
	3. 1.8 гб - логический том для bios. Напрямую монтирует в диск.

-- **Запуск с виртуального диск с установленной ОС**
```bash
qemu-system-x86_64 -hda my_virtual_disk.qcow2 -m 4G -enable-kvm
```
Теперь новые данные будут сохраняться, потому что они будут сохраняться в физической памяти, а не в ram


-- **Проблемы с доступом в интернет из ВМ**
Для того, чтобы все работало, нужно добавить доп параметры: 
`-netdev user,id=net0 -device e1000,netdev=net0`

```shell
qemu-system-x86_64 -hda my_virtual_disk.qcow2 -m 4G -enable-kvm -netdev user,id=net0 -device e1000,netdev=net0
```

После чего на ВМ появятся все нужные интерфейсы и роуты
![[Pasted image 20250427172755.png]]
### Общение ВМ через хоста и через мост
- **"Через хоста"**: Запрос проходит через сетевую инфраструктуру хоста, где хост выступает в роли маршрутизатора или шлюза. Например, если ВМ используют NAT или Host-Only сеть, трафик сначала идет на хост, а затем перенаправляется на другую ВМ.
    
- **"Через виртуальный мост (bridge)"**: Виртуальные машины подключены к общему виртуальному bridge-интерфейсу, который эмулирует физический коммутатор. В этом случае ВМ могут взаимодействовать напрямую, как если бы они были подключены к одному физическому сегменту сети. Хост не участвует в маршрутизации, а только предоставляет bridge.

### Примеры
#### Запрос от вм до хоста
-- **Сервер на хосте**
```bash
python3 -m http.server 8080
```
-- **Настройки сети VM**
```bash
andrey@server:~$ ip addr show
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: ens3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 52:54:00:12:34:56 brd ff:ff:ff:ff:ff:ff
    altname enp0s3
    altname enx525400123456
    inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic ens3
       valid_lft 86286sec preferred_lft 86286sec
    inet6 fec0::5054:ff:fe12:3456/64 scope site dynamic mngtmpaddr noprefixroute
       valid_lft 86286sec preferred_lft 14288sec
    inet6 fe80::5054:ff:fe12:3456/64 scope link proto kernel_ll
       valid_lft forever preferred_lft forever
andrey@server:~$ ip route show
default via 10.0.2.2 dev ens3 proto dhcp src 10.0.2.15 metric 100
10.0.2.0/24 dev ens3 proto kernel scope link src 10.0.2.15 metric 100
10.0.2.2 dev ens3 proto dhcp scope link src 10.0.2.15 metric 100
```
-- **Отправление запроса из VM**
